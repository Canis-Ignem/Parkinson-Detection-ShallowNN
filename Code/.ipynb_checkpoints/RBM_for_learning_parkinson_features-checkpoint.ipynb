{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using an RMB to learn parkinson features\n",
    "\n",
    "In this notebook I will tackle the problem of letting an RMB learn features that I will use to train an MLP in order to solve the Parkinson detection problem. Please note that this notebook contains only one of the three proposed solutions, in order to get a complete view you should check the other notebook and the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "The main goal is to let the RMB learn the features but in previous attemps when giving it all the data and etting it trainit didn't manage to learn anything. So I will be reusing most of the previously used feature selection techniques. If you have any doubts pls check the other notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will follow the same procesdure that was followes in the other notebook with the exception that I will not be using the variance or the test_id for the RMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_path = \"Data/control\"\n",
    "parkinson_path = \"Data/parkinson\"\n",
    "\n",
    "\n",
    "def getFiles(path):\n",
    "    all_files = glob.glob(path + \"/*.txt\")\n",
    "    data = []\n",
    "\n",
    "    for file in all_files:\n",
    "        df = pd.read_csv(file,sep=\";\")\n",
    "        data.append(df)\n",
    "    \n",
    "    return data\n",
    "         \n",
    "\n",
    "def extractFeatures(df):\n",
    "    features = []\n",
    "    features.append(np.argmax( df.values[:,0]) - np.argmin( df.values[:,0]))\n",
    "    features.append(np.argmax( df.values[:,1]) - np.argmin( df.values[:,1]))\n",
    "    features.append(np.argmax( df.values[:,2]) - np.argmin( df.values[:,2]))\n",
    "    features.append(np.argmax( df.values[:,3]) - np.argmin( df.values[:,3]))\n",
    "    features.append(np.argmax( df.values[:,4]) - np.argmin( df.values[:,4]))\n",
    "    return features\n",
    "    \n",
    "\n",
    "def getControlFeatures():\n",
    "    control_data = []\n",
    "    control = getFiles(control_path)\n",
    "    for i in control:\n",
    "        new_df = splitByTest(i)\n",
    "        for k in range(new_df.shape[0]):\n",
    "            last_df = np.array_split(i,40)\n",
    "            for j in last_df:\n",
    "                control_data.append(extractFeatures(j))\n",
    "    return pd.DataFrame(control_data)\n",
    "\n",
    "\n",
    "def getParkinsonFeatures():\n",
    "    parkinson_data = []\n",
    "    parkinson = getFiles(parkinson_path)\n",
    "    for i in parkinson:\n",
    "        new_df = splitByTest(i)\n",
    "        for k in range(new_df.shape[0]):\n",
    "            last_df = np.array_split(i,40)\n",
    "            for j in last_df:\n",
    "                parkinson_data.append(extractFeatures(j))\n",
    "    return pd.DataFrame(parkinson_data)\n",
    "\n",
    "\n",
    "def getClasses(control, parkinson):\n",
    "    classes = []\n",
    "    for i in range(control.shape[0]):\n",
    "        classes.append(0)\n",
    "    for i in range(parkinson.shape[0]):\n",
    "        classes.append(1)\n",
    "    res = np.array(classes)\n",
    "\n",
    "    return res\n",
    "\n",
    "def splitByTest(df):\n",
    "    data = []\n",
    "    test = df.values[0][6]\n",
    "    split = []\n",
    "    cont = 0\n",
    "    for i in range(df.shape[0]):\n",
    "        if df.values[i][6] == test:\n",
    "            split.append(df.values[i])\n",
    "        else:\n",
    "            aux = pd.DataFrame(split)\n",
    "            data.append(aux)\n",
    "            split = []\n",
    "            test = df.values[i][6]\n",
    "            split.append(df.values[i])\n",
    "    data.append(split)\n",
    "    return pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBM and MLP pipeline\n",
    "\n",
    "I decided to used the RMB that is abailable in SKlearn, which is the Bernoulli Restricted Blotzmann machine, I will create a pipeline with this RBM and skelarn MLPClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's set up the RBM's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm = BernoulliRBM( verbose=True)\n",
    "\n",
    "rbm.learning_rate = 0.0002\n",
    "rbm.n_iter = 300\n",
    "\n",
    "rbm.n_components = 200"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
